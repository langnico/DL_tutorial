{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN tutorial\n",
    "\n",
    "This part of the tutorial will introduce a simple Convolutional Neural Network (CNN) architecture to classify images.\n",
    "You will extend the given architecture with your own ideas to improve the performance of the classifier. Finally, you can train a state-of-the-art CNN (ResNet50) by fine-tuning a model that was trained on ImageNet.\n",
    "As a toy example we use the cifar10 dataset. (source: https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "Run the code cell by cell individually and complete the missing parts. Carry out the experiments and answer the questions. Have fun!\n",
    "\n",
    "If you are waiting while a model is training, have a break on the playground and explore the effects of hyperparameters: https://playground.tensorflow.org\n",
    "\n",
    "### Tasks:\n",
    "1. Complement the model architecture given in the Figure (AlexNet like architecture).\n",
    "2. Train and evaluate the network on the original input images (RGB)\n",
    "3. Train and evaluate on the preprocessed input data\n",
    "    * Why is preprocessing the input data important?\n",
    "4. Modify and extend the CNN model architecture to improve performance and beat our baseline. For example:    \n",
    "    * higher model capacity\n",
    "    * stronger non-linearity (increase model depth/ # layers)\n",
    "    * stronger pooling (shrinkage -> global information)\n",
    "    * stronger regularization (dropout)\n",
    "5. Train and evaluate the modified model on the preprocessed input data\n",
    "\n",
    "#### Bonus / Homework ;-)\n",
    "\n",
    "6. Train and evaluate the modified model using data augmentation at train time \n",
    "    * We use the data augmentation generator from keras (ImageDataGenerator)\n",
    "    * Use the template below and set meaningful data augmentation parameters\n",
    "    * Did the data augmentation improve performance? Can you explain why?\n",
    "    * In what scenario might data augmentation be very useful?\n",
    "7. Run the ResNet50 model and compare the performance to our simple and shallow CNN model\n",
    "    * Compare the performance and the training curves to the previous models (AlexNet)?\n",
    "    * Can you observe overfitting?\n",
    "    * What could be tried to improve the performance of the ResNet50 model on the cifar10 dataset?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras import initializers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET PARAMETERS\n",
    "data_dir = 'data/'  # relative path to the subdirectory\n",
    "nb_classes = 10\n",
    "img_rows, img_cols, channels = 32, 32, 3  # input image dimensions for the cifar10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image data (cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cifar10 training and test sets from keras\n",
    "# from keras.datasets import cifar10\n",
    "# (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Load cifar10 from local file\n",
    "cifar10_data = np.load(data_dir + '/cifar10.npz')\n",
    "X_train = cifar10_data['X_train']\n",
    "y_train = cifar10_data['y_train']\n",
    "X_test = cifar10_data['X_test']\n",
    "y_test = cifar10_data['y_test']\n",
    "\n",
    "\n",
    "# if grey scale images: data dimensions are not [images, height, width, channels] then add 1 dimension for channels\n",
    "if len(X_train.shape) == 3:\n",
    "    print('X_train original shape:', X_train.shape)\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "    X_test = np.expand_dims(X_test, axis=3)\n",
    "    print('X_train expanded shape:', X_train.shape)\n",
    "\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    # For Theano backend\n",
    "    X_train = X_train.reshape(X_train.shape[0], channels, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], channels, img_rows, img_cols)\n",
    "    input_shape = (channels, img_rows, img_cols)\n",
    "else:\n",
    "    # For TensorFlow backend\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, channels)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, channels)\n",
    "    input_shape = (img_rows, img_cols, channels)\n",
    "    \n",
    "print(X_train.shape, 'train samples')\n",
    "print(X_test.shape, 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into validation and train \n",
    "# --> split (X_train, y_train) into (X_train, y_train) and (X_val, y_val)\n",
    "nb_train_images = X_train.shape[0]\n",
    "shuffled_indices = np.arange(nb_train_images)\n",
    "np.random.shuffle(shuffled_indices)\n",
    "train_indices = shuffled_indices[:int(0.8*nb_train_images)]      # 80% for training\n",
    "val_indices = shuffled_indices[int(0.8*nb_train_images):]        # 20% for validation\n",
    "\n",
    "X_val = X_train[val_indices, :, :, :]\n",
    "y_val = y_train[val_indices]\n",
    "\n",
    "X_train = X_train[train_indices, :, :, :]\n",
    "y_train = y_train[train_indices]\n",
    "\n",
    "print(X_train.shape, 'train samples')\n",
    "print(X_val.shape, 'val samples')\n",
    "print(X_test.shape, 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE IMAGES\n",
    "def plotImages( images, n_images=8):\n",
    "    fig, axes = plt.subplots(n_images, n_images, figsize=(10, 10))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plotImages(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "Y_val = np_utils.to_categorical(y_val, nb_classes)\n",
    "\n",
    "print('label integer encoded: y_train[0]: ', y_train[0])\n",
    "print('label one-hot encoded: Y_train[0]: ', Y_train[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model - AlexNet \n",
    "\n",
    "**Task**: Implement an AlexNet like CNN as visualized in the Figure below. \n",
    "\n",
    "* Use strides=(1,1) for all convolutional layers. \n",
    "* Use 'relu' as activation for both, conv and dense (fully connected) layers. \n",
    "* Spatial extent is reduced by using maxpooling. Set the pool_size0(3,3) and set the parameter strides, such that the spatial extent is reduced by factor 2 in both spatial dimensions.\n",
    "* For both dense layers use 128 neurons instead of 4096 to reduce the number of parameters for this tutorial.\n",
    "* Add dropout layers after the first and second convolutional layer as well as after both dense layers. Use the given dropout probabilities `prob_drop_conv = 0.2` and `prob_drop_hidden = 0.5`.\n",
    "\n",
    "**Questions to answer**:\n",
    "\n",
    "1. How does the Total number of trainable parameters change, when we change the number of neurons in the first dense layer from 128 to the original proposed 4096?\n",
    "2. AlexNet was designed for ImageNet input images with a size of 224x224 pixels. Concerning the first convolutional layer, what could we change to adapt better to our dataset?\n",
    "\n",
    "![title](figures/alexnet.png)\n",
    "*Figure 1: Visualization of the AlexNet(-like) architecture for the ImageNet challenge (1000 classes)*\n",
    "\n",
    "\n",
    "img source: http://cv-tricks.com/wp-content/uploads/2017/03/xalexnet_small-1.png.pagespeed.ic.q5Lnn1-u6h.png\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "base_learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "\n",
    "pool_size = (3, 3)                  # size of pooling area for max pooling\n",
    "prob_drop_conv = 0.2                # drop probability for dropout @ conv layer\n",
    "prob_drop_hidden = 0.5              # drop probability for dropout @ fc layer\n",
    "\n",
    "def AlexNet():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # conv1 layer\n",
    "    conv1 = Conv2D(filters=96, kernel_size=(11, 11), strides=(1,1), padding='same', activation='relu', \n",
    "                   input_shape=input_shape)\n",
    "    model.add(conv1)\n",
    "    model.add(MaxPooling2D(pool_size=(pool_size), strides=(2, 2), padding='same'))\n",
    "    model.add(Dropout(prob_drop_conv))\n",
    "\n",
    "    # TODO ...\n",
    "    \n",
    "    \n",
    "    \n",
    "    # the output of the last conv layer is flattend from a Volume to a 1D-array\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # TODO ...\n",
    "\n",
    "    \n",
    "    \n",
    "    # fc3 layer\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model_alexNet = AlexNet()\n",
    "model_alexNet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of batches per epoch. \n",
    "# One epoch is defined as an update pass through the full training data. \n",
    "# One iteration is defined as an update through one mini-batch.\n",
    "batches_per_epoch = X_train.shape[0]//batch_size\n",
    "# the number of batches to see the full validation data:\n",
    "validation_steps = X_val.shape[0]//batch_size\n",
    "print('number of images per batch: {}'.format(batch_size))\n",
    "print('batches per epoch: {}'.format(batches_per_epoch))\n",
    "print('validation steps: {}'.format(validation_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator to load the training data as batches\n",
    "\n",
    "def generator(features, labels, batch_size, patch_size, channels, nb_classes):\n",
    " # Create empty arrays to contain batch of features and labels#\n",
    " batch_features = np.zeros((batch_size, patch_size, patch_size, channels))\n",
    " batch_labels = np.zeros((batch_size, nb_classes))\n",
    "\n",
    " while True:\n",
    "    for i in range(batch_size):\n",
    "         # choose random index in features\n",
    "         index = np.random.choice(a=features.shape[0], size=1)\n",
    "\n",
    "         #Optional: Add some data augmentation here\n",
    "\n",
    "         batch_features[i] = features[index, :, :, :]\n",
    "         batch_labels[i] = labels[index]\n",
    "    yield batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to re-initialize the weights before starting a new experiment/training\n",
    "\n",
    "def initialize_weights(model, layer_name=None):\n",
    "    session = K.get_session()\n",
    "    if layer_name is None:\n",
    "        for layer in model.layers: \n",
    "            if hasattr(layer, 'kernel_initializer'):\n",
    "                print('initialize weights of layer: {}'.format(layer.name))\n",
    "                layer.kernel.initializer.run(session=session)\n",
    "    else:\n",
    "        layer = model.get_layer(name=layer_name)\n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            print('initialize weights of layer: {}'.format(layer.name))\n",
    "            layer.kernel.initializer.run(session=session)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to plot training curves\n",
    "\n",
    "def plot_train_val_accuracy_and_loss(history, legend_suffix=\"\"):\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_'+legend_suffix, 'val_'+legend_suffix], loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_'+legend_suffix, 'val_'+legend_suffix], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model on original data\n",
    "\n",
    "The model was trained on a GPU (Titan Xp 12GB) for 11 epochs within 99 seconds (9 seconds per epoch). This code loads the weights after the 11th epoch. You will train one epoch more and then the training/validation curves are plotted for the entire 12 epochs. \n",
    "\n",
    "If you have not implemented the model correctly the weights of the pre-trained model will not match the model architecture. \n",
    "\n",
    "* Did the model learn anything yet? Is it better than a random classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 1 # 4\n",
    "model=AlexNet()\n",
    "opt = Adam(lr=base_learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "# load the model weights from epoch 11\n",
    "weights_path = 'model_weights/alexnet_original_epoch11.h5'\n",
    "model.load_weights(filepath=weights_path, by_name=False, skip_mismatch=False)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# re-initialize weights of the model to train from scratch\n",
    "#initialize_weights(model)\n",
    "\n",
    "history_original = model.fit_generator(\n",
    "        generator(features=X_train, labels=Y_train, batch_size=batch_size, patch_size=img_cols, channels=channels, \n",
    "                  nb_classes=nb_classes),\n",
    "        steps_per_epoch=batches_per_epoch, epochs=nb_epoch, \n",
    "        validation_data=generator(features=X_val, labels=Y_val, batch_size=batch_size, patch_size=img_cols, \n",
    "                                  channels=channels, nb_classes=nb_classes),\n",
    "        validation_steps=validation_steps)\n",
    "\n",
    "# merge history until epoch_11 with additional epoch\n",
    "history_epoch11 = {'acc': [0.11380709134615384, 0.13599258814102563, 0.19721554487179488, 0.2645983573717949, 0.328700921474359, 0.3811848958333333, 0.4226262019230769, 0.4607121394230769, 0.49291366185897434, 0.5213842147435898, 0.5494791666666666], 'loss': [2.864764799674352, 2.2487578705335274, 2.1015444237452288, 1.962251861890157, 1.823481919291692, 1.7024982212445674, 1.604735214358721, 1.525293638690924, 1.4359341340187268, 1.3694841491106229, 1.3113467792669933], 'val_acc': [0.17057291666666666, 0.23537660256410256, 0.34825721153846156, 0.4004407051282051, 0.43569711538461536, 0.4668469551282051, 0.49328926282051283, 0.5360576923076923, 0.5328525641025641, 0.5571915064102564, 0.5865384615384616], 'val_loss': [2.271790779553927, 2.125739351297036, 1.9180474495276427, 1.7726084635807917, 1.6616307405325084, 1.5195633050722954, 1.476634464202783, 1.3749462304971156, 1.3630957527038379, 1.3458387286235125, 1.2366121120941944]}\n",
    "for key in history_original.history.keys():\n",
    "    history_original.history[key] = history_epoch11[key] + history_original.history[key]\n",
    "    \n",
    "plot_train_val_accuracy_and_loss(history_original, legend_suffix='original')\n",
    "    \n",
    "# model.save_weights('model_weights/alexnet_original_epoch11.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model trained on the original data\n",
    "evaluation = model.evaluate(X_test, Y_test, batch_size=256, verbose=1)\n",
    "print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the input images\n",
    "\n",
    "We subtract the training mean and divide by the training standard deviation for each RGB channel separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING: NORMALIZE THE INPUT DATA\n",
    "# as calculating the Mean and STD over the entire training data takes some time, the values are provide.\n",
    "\n",
    "def get_mean_and_std_per_channel(data_train, patch_size, channels=3):\n",
    "    N = data_train.shape[0]\n",
    "    img_concat = None\n",
    "    for i in range(data_train.shape[0]):\n",
    "        img = data_train[i, :, :, :]\n",
    "        print(i)\n",
    "        assert len(img.shape) == 3\n",
    "\n",
    "        if img_concat is None:\n",
    "            img_concat = img\n",
    "        else:\n",
    "            img_concat = np.concatenate((img_concat, img), axis=0)\n",
    "\n",
    "    assert img_concat.shape == (N * patch_size, patch_size, channels)\n",
    "    print('img_concat.shape', img_concat.shape)\n",
    "\n",
    "    # calculate mean\n",
    "    mean = np.mean(img_concat, axis=(0, 1))\n",
    "    mean = mean.reshape(1, 1, channels)\n",
    "    print('mean: ', mean)\n",
    "    print('mean.shape', mean.shape)\n",
    "    assert mean.shape == (1, 1, channels)\n",
    "\n",
    "    # control mean\n",
    "    img_concat_zero_mean = img_concat - np.tile(mean, [N * patch_size, patch_size, 1])\n",
    "    mean_control = np.mean(img_concat_zero_mean, axis=(0, 1))\n",
    "    print('mean_control', mean_control)\n",
    "\n",
    "    # calculate std\n",
    "    std = np.std(img_concat_zero_mean, axis=(0, 1))\n",
    "    std = std.reshape(1, 1, channels)\n",
    "    print('std: ', std)\n",
    "    print('std.shape', std.shape)\n",
    "    assert std.shape == (1, 1, channels)\n",
    "\n",
    "    # control std\n",
    "    img_concat_zero_mean_std_1 = np.divide(img_concat_zero_mean, np.tile(std, [N * patch_size, patch_size, 1]))\n",
    "    std_control = np.std(img_concat_zero_mean_std_1, axis=(0, 1))\n",
    "    print('std_control: ', std_control)\n",
    "    return mean, std\n",
    "\n",
    "def normalize_img_per_channel(image, mean_train, std_train, patch_size):\n",
    "    img_zero_mean = image - np.tile(mean_train, [patch_size, patch_size, 1])\n",
    "    img_norm = np.divide(img_zero_mean, np.tile(std_train, [patch_size, patch_size, 1]))\n",
    "    return img_norm\n",
    "\n",
    "def normalize_images_per_channel(images, mean_train, std_train, out_dtype='float32'):\n",
    "    images_norm = []\n",
    "    for i in range(images.shape[0]):\n",
    "        img = images[i, :, :, :]\n",
    "        assert len(img.shape) == 3\n",
    "        img_norm = normalize_img_per_channel(img, mean_train, std_train, patch_size=img.shape[0])\n",
    "        images_norm.append(img_norm)\n",
    "    return np.asarray(images_norm, out_dtype)\n",
    "\n",
    "# print('calculating mean and std per channel from the training data...')\n",
    "# mean_train_file = data_dir + '/cifar10_mean_train.npy'\n",
    "# std_train_file = data_dir + '/cifar10_std_train.npy'\n",
    "# MEAN_train, STD_train = get_mean_and_std_per_channel(data_train=X_train, patch_size=img_cols, channels=channels)\n",
    "# np.save(mean_train_file, MEAN_train)\n",
    "# np.save(std_train_file, STD_train)\n",
    "# #load mean, std from file\n",
    "# MEAN_train = np.load(mean_train_file)\n",
    "# STD_train = np.load(std_train_file)\n",
    "\n",
    "# Cifar10 mean and std from training data\n",
    "MEAN_train = [[[125.30691805, 122.95039414, 113.86538318]]]\n",
    "STD_train = [[[62.99321928, 62.08870764, 66.70489964]]]\n",
    "\n",
    "X_train_prepro = normalize_images_per_channel(images=X_train, mean_train=MEAN_train, std_train=STD_train, \n",
    "                                              out_dtype='float32')\n",
    "X_test_prepro = normalize_images_per_channel(images=X_test, mean_train=MEAN_train, std_train=STD_train, \n",
    "                                             out_dtype='float32')\n",
    "X_val_prepro = normalize_images_per_channel(images=X_val, mean_train=MEAN_train, std_train=STD_train, \n",
    "                                            out_dtype='float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model on preprocessed images\n",
    "\n",
    "The model was trained on a GPU (Titan Xp 12GB) for 11 epochs within 99 seconds (9 seconds per epoch). This code loads the weights after the 11th epoch. You will train one epoch more and then the training/validation curves are plotted for the entire 12 epochs. \n",
    "\n",
    "If you have not implemented the model correctly the weights of the pre-trained model will not match the model architecture. \n",
    "\n",
    "* What is the purpose of preprocessing the input data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the model with preprocessed images\n",
    "import time\n",
    "nb_epoch = 1 \n",
    "\n",
    "model=AlexNet()\n",
    "opt = Adam(lr=base_learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "# load the model weights from epoch 11\n",
    "weights_path = 'model_weights/alexnet_prepro_epoch11.h5'\n",
    "model.load_weights(filepath=weights_path, by_name=False, skip_mismatch=False)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# re-initialize the weights of the model to train again from scratch\n",
    "# initialize_weights(model)\n",
    "\n",
    "history_preprocessed = model.fit_generator(\n",
    "        generator=generator(features=X_train_prepro, labels=Y_train, batch_size=batch_size, patch_size=img_cols, \n",
    "                            channels=channels, nb_classes=nb_classes),\n",
    "        steps_per_epoch=batches_per_epoch, epochs=nb_epoch, \n",
    "        validation_data=generator(features=X_val_prepro, labels=Y_val, batch_size=batch_size, patch_size=img_cols, \n",
    "                                  channels=channels, nb_classes=nb_classes),\n",
    "        validation_steps=validation_steps)\n",
    "end = time.time()\n",
    "\n",
    "# merge history until epoch_11 with additional epoch\n",
    "history_epoch11 = {'acc': [0.2156700721153846, 0.3423477564102564, 0.42630709134615385, 0.48645332532051283, 0.5366336137820513, 0.5784505208333334, 0.6115284455128205, 0.6462089342948718, 0.6648888221153846, 0.6934595352564102, 0.7147185496794872], 'loss': [2.089567707135127, 1.7973418403894474, 1.5924712048891263, 1.4378445916450941, 1.3178296906825824, 1.21250919959484, 1.1237694015487647, 1.0532857810075467, 0.9948647719545242, 0.929585806452311, 0.8595956252553524], 'val_acc': [0.3524639423076923, 0.4524238782051282, 0.49689503205128205, 0.5552884615384616, 0.5911458333333334, 0.6274038461538461, 0.6372195512820513, 0.625, 0.6810897435897436, 0.6893028846153846, 0.7086338141025641], 'val_loss': [1.8619595368703206, 1.5888427159725091, 1.4259456885166657, 1.2888002365063398, 1.2032615458353972, 1.1024081195012116, 1.0880448734148955, 1.0802756013014378, 0.982640591951517, 0.9475753979805188, 0.9044325435772921]}\n",
    "for key in history_preprocessed.history.keys():\n",
    "    history_preprocessed.history[key] = history_epoch11[key] + history_preprocessed.history[key]\n",
    "\n",
    "plot_train_val_accuracy_and_loss(history_preprocessed, legend_suffix='preprocessed')\n",
    "\n",
    "#model.save_weights('model_weights/alexnet_prepro_epoch11.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model trained on preprocessed input data\n",
    "evaluation = model.evaluate(X_test_prepro, Y_test, batch_size=256, verbose=1)\n",
    "print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the performance w/ and w/o preprocessing the input images\n",
    "\n",
    "What is the purpose of preprocessing the input images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all histories and plot all curves in same figure\n",
    "# comment: we skipt the result on the original data, as the model performance was poor\n",
    "\n",
    "history_list = [history_original, history_preprocessed]\n",
    "legend_suffix_list = ['original', 'preprocessed']\n",
    "\n",
    "# plot accuracy curves\n",
    "acc_legend = []\n",
    "for history, legend_suffix in zip(history_list, legend_suffix_list):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    acc_legend += ['train_'+legend_suffix, 'val_'+legend_suffix]\n",
    "plt.legend(acc_legend, loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# plot loss curves\n",
    "loss_legend = []\n",
    "for history, legend_suffix in zip(history_list, legend_suffix_list):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    loss_legend += ['train_'+legend_suffix, 'val_'+legend_suffix]\n",
    "plt.legend(loss_legend, loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend the AlexNet like architecture\n",
    "Copy the AlexNet architecture from above into the template AlexNet_modified() and modify/extend it to improve the performance. \n",
    "\n",
    "Possible modifications:    \n",
    "* higher model capacity\n",
    "* stronger non-linearity (increase model depth/ # layers)\n",
    "* stronger pooling (shrinkage -> global information)\n",
    "* stronger regularization (dropout)\n",
    "    \n",
    "Hint: Try to build a deeper model without increasing the number of parameters too much.\n",
    "\n",
    "* Compare the number of parameters to the previous model. Which layers introduce most of the parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One possible solution\n",
    "base_learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "\n",
    "pool_size = (3, 3)                  # size of pooling area for max pooling\n",
    "prob_drop_conv = 0.2                # drop probability for dropout @ conv layer\n",
    "prob_drop_hidden = 0.5              # drop probability for dropout @ fc layer\n",
    "\n",
    "def AlexNet_modified():\n",
    "\n",
    "    # TODO ... implement your own CNN here\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "model_alexNet_mod = AlexNet_modified()\n",
    "model_alexNet_mod.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the modified AlexNet on preprocessed data\n",
    "\n",
    "* Could you improve the performance?\n",
    "* What changed concerning the convergence time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TRAIN the model again\n",
    "# NEW: PREPROCESSED INPUT IMAGES\n",
    "\n",
    "nb_epoch = 12 # 12\n",
    "\n",
    "model = AlexNet_modified()\n",
    "opt = Adam(lr=base_learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# re-initialize the weights of the model to train again from scratch\n",
    "initialize_weights(model)\n",
    "\n",
    "history_preprocessed_modified = model.fit_generator(\n",
    "        generator=generator(features=X_train_prepro, labels=Y_train, batch_size=batch_size, patch_size=img_cols, \n",
    "                            channels=channels, nb_classes=nb_classes),\n",
    "        steps_per_epoch=batches_per_epoch, epochs=nb_epoch, \n",
    "        validation_data=generator(features=X_val_prepro, labels=Y_val, batch_size=batch_size, patch_size=img_cols, \n",
    "                                  channels=channels, nb_classes=nb_classes),\n",
    "        validation_steps=validation_steps)\n",
    "\n",
    "plot_train_val_accuracy_and_loss(history_preprocessed_modified, legend_suffix='preprocessed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model trained on preprocessed input data\n",
    "evaluation = model.evaluate(X_test_prepro, Y_test, batch_size=256, verbose=1)\n",
    "print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the performance of your modified model with the AlexNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_list = [history_preprocessed, history_preprocessed_modified]\n",
    "legend_suffix_list = ['AlexNet', 'AlexNet_modified']\n",
    "\n",
    "# plot accuracy curves\n",
    "acc_legend = []\n",
    "for history, legend_suffix in zip(history_list, legend_suffix_list):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    acc_legend += ['train_'+legend_suffix, 'val_'+legend_suffix]\n",
    "plt.legend(acc_legend, loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# plot loss curves\n",
    "loss_legend = []\n",
    "for history, legend_suffix in zip(history_list, legend_suffix_list):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    loss_legend += ['train_'+legend_suffix, 'val_'+legend_suffix]\n",
    "plt.legend(loss_legend, loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following is thought as a bonus exercise ... or homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Data augmentation: Train the modified AlexNet using data augmentation\n",
    "\n",
    "A common trick to improve performance is to use data augmentation at train time. Let's try:\n",
    "\n",
    "The keras ImageDataGenerator provides an image generator with built in data augmentation: https://keras.io/preprocessing/image/\n",
    "\n",
    "Set meaningful data augmentation parameters.\n",
    "\n",
    "* Did the data augmentation improve performance? Can you explain why?\n",
    "* In what scenario might data augmentation be very useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TRAIN the model again with data augmentation\n",
    "\n",
    "nb_epoch = 24 # 26\n",
    "\n",
    "model = AlexNet_modified()\n",
    "opt = Adam(lr=base_learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# TODO\n",
    "# image generator for data augmentation. Documentation: https://keras.io/preprocessing/image/\n",
    "image_gen = ImageDataGenerator(\n",
    "    width_shift_range=5,   # pixel\n",
    "    height_shift_range=5,  # pixel\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# re-initialize weights of the model before training again\n",
    "initialize_weights(model)\n",
    "\n",
    "history_augmented = model.fit_generator(\n",
    "        generator=image_gen.flow(X_train_prepro, Y_train, batch_size=batch_size),\n",
    "        steps_per_epoch=batches_per_epoch,\n",
    "        epochs=nb_epoch,\n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        validation_data=generator(features=X_val_prepro, labels=Y_val, batch_size=batch_size, patch_size=img_cols, \n",
    "                                  channels=channels, nb_classes=nb_classes),\n",
    "        validation_steps=validation_steps)\n",
    "\n",
    "plot_train_val_accuracy_and_loss(history_augmented, legend_suffix='augmented')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model trained with augmented training data\n",
    "evaluation = model.evaluate(X_test_prepro, Y_test, batch_size=256, verbose=1)\n",
    "print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Compare the performance w/ and w/o data augmentation\n",
    "\n",
    "Did the data augmentation improve performance? Can you explain why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all histories and plot all curves in same figure\n",
    "# comment: we skipt the result on the original data, as the model performance was poor\n",
    "\n",
    "history_list = [history_preprocessed, history_augmented]\n",
    "legend_suffix_list = ['preprocessed', 'augmented']\n",
    "\n",
    "# plot accuracy curves\n",
    "acc_legend = []\n",
    "for history, legend_suffix in zip(history_list, legend_suffix_list):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    acc_legend += ['train_'+legend_suffix, 'val_'+legend_suffix]\n",
    "plt.legend(acc_legend, loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# plot loss curves\n",
    "loss_legend = []\n",
    "for history, legend_suffix in zip(history_list, legend_suffix_list):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    loss_legend += ['train_'+legend_suffix, 'val_'+legend_suffix]\n",
    "plt.legend(loss_legend, loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: ResNet50\n",
    "\n",
    "The remaining code trains the ResNet50 model for the cifar10 dataset. We use a pre-trained model on ImageNet to initialize our weights and finetune the model.\n",
    "\n",
    "As we are working with small input images (32x32 pixels) this version of the ResNet50 has modified strides, such that the spatial extent of the feature maps is not reduced too much.\n",
    "\n",
    "code source: https://github.com/flyyufelix/cnn_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"\n",
    "    The identity_block is the block that has no conv layer at shortcut\n",
    "    Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    \"\"\"\n",
    "\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters=nb_filter1, kernel_size=(1, 1), name=conv_name_base + '2a')(input_tensor)\n",
    "\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters=nb_filter2, kernel_size=(kernel_size, kernel_size), \n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters=nb_filter3, kernel_size=(1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = merge([x, input_tensor], mode='sum')\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    \"\"\"\n",
    "    conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
    "    And the shortcut should have subsample=(2,2) as well\n",
    "    \"\"\"\n",
    "\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters=nb_filter1, kernel_size=(1, 1), strides=strides,\n",
    "                      name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters=nb_filter2, kernel_size= (kernel_size, kernel_size), padding='same',\n",
    "                      name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters=nb_filter3, kernel_size=(1, 1), name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters=nb_filter3, kernel_size=(1, 1), strides=strides,\n",
    "                             name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = merge([x, shortcut], mode='sum')\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def ResNet50(img_input):\n",
    "    model = Sequential()\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2), name='conv1', padding='same')(img_input)\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "    \n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "    \n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # Fully Connected Softmax Layer\n",
    "    x_fc = AveragePooling2D((3, 3), name='avg_pool')(x)\n",
    "    x_fc = Flatten()(x_fc)\n",
    "    x_fc = Dense(nb_classes, activation='softmax', name='cifar10_logits')(x_fc)\n",
    "\n",
    "    model = Model(img_input, x_fc)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "if K.image_dim_ordering() == 'tf':\n",
    "  bn_axis = 3\n",
    "  img_input = Input(shape=(img_rows, img_cols, channels))\n",
    "else:\n",
    "  bn_axis = 1\n",
    "  img_input = Input(shape=(color_type, img_rows, channels))\n",
    "\n",
    "my_model = ResNet50(img_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning: Initialize the model with pre-trained weights from a model trained on ImageNet dataset\n",
    "ImageNet: http://image-net.org/about-overview\n",
    "\n",
    "ResNet50 weights pre-trained on ImageNet can be downloaded here: https://github.com/flyyufelix/cnn_finetune\n",
    "\n",
    "Save the weights file (.h5) in the following directory: pretrained_models_imageNet (or change the `weights_path` accordingly)\n",
    "\n",
    "We initialize the layer weights from the pre-trained model by layer name. In the final dense layer, we set the number of classes to 10 to solve our cifar10 task. Therefore, the number of parameters has changed compared to the pre-trained model with 1000 classes from another task. By changing the layer name to 'cifar10_logits', the final layer is not initialized from the pre-trained model, but with random weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_learning_rate = 0.001\n",
    "opt = Adam(lr=base_learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "weights_path='pretrained_models_imageNet/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "\n",
    "my_model.load_weights(filepath=weights_path, by_name=True, skip_mismatch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix all layers except the final dense layer (and batch_norm layers)\n",
    "\n",
    "For the final dense layer, we do not have a good initialization yet. This layer will be initialized randomly. If we would train the new final layer as well as all ohter layers with good initialization together, the random weights from the new layer could deteriorate the already good featrues from our pre-trained model. One way to avoid this, is to fix all layer weights during the training and update only the weights for the last dense layer. Once we have a decent classifier, we allow also all other weights to update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train only the final dense layer and keep all other layers fixed (except the batch_norm)\n",
    "print('total number of layers:', len(my_model.layers))\n",
    "for layer in my_model.layers[:-1]:\n",
    "    if not 'bn' in layer.name: # we need to update the batch_norm layers anyways\n",
    "        print(layer.name)\n",
    "        layer.trainable = False # can be set to False to fix the weights during training\n",
    "\n",
    "my_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the weights of the final dense layer (before training)\n",
    "initialize_weights(my_model, layer_name='cifar10_logits')\n",
    "w = my_model.get_layer(name='cifar10_logits').get_weights()\n",
    "plt.figure()\n",
    "n, bins, patches = plt.hist(w, bins=501, facecolor='green', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the ResNet50 model with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# image generator for data augmentation. Documentation: https://keras.io/preprocessing/image/\n",
    "image_gen = ImageDataGenerator(\n",
    "    width_shift_range=5,   # pixel\n",
    "    height_shift_range=5,  # pixel\n",
    "    horizontal_flip=True)\n",
    "\n",
    "\n",
    "nb_epoch = 4 # 26\n",
    "\n",
    "history_augmented = my_model.fit_generator(\n",
    "        generator=image_gen.flow(X_train_prepro, Y_train, batch_size=batch_size),\n",
    "        steps_per_epoch=batches_per_epoch,\n",
    "        epochs=nb_epoch,\n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        validation_data=generator(features=X_val_prepro, labels=Y_val, batch_size=batch_size, patch_size=img_cols, \n",
    "                                  channels=channels, nb_classes=nb_classes),\n",
    "        validation_steps=validation_steps)\n",
    "\n",
    "plot_train_val_accuracy_and_loss(history_augmented, legend_suffix='augmented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model trained with augmented training data\n",
    "evaluation = my_model.evaluate(X_test_prepro, Y_test, batch_size=256, verbose=1)\n",
    "print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the learned weights of the final dense layer (after training)\n",
    "w = my_model.get_layer(name='cifar10_logits').get_weights()\n",
    "plt.figure()\n",
    "n, bins, patches = plt.hist(w, bins=500, facecolor='green', alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allow all layers to update the weights during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train all the other layers as well\n",
    "print('total number of layers:', len(my_model.layers))\n",
    "for layer in my_model.layers[:]:\n",
    "    print(layer.name)\n",
    "    layer.trainable = True # can be set to False to fix the weights during training\n",
    "    \n",
    "nb_epoch = 12     \n",
    "    \n",
    "history_augmented = my_model.fit_generator(\n",
    "        generator=image_gen.flow(X_train_prepro, Y_train, batch_size=batch_size),\n",
    "        steps_per_epoch=batches_per_epoch,\n",
    "        epochs=nb_epoch,\n",
    "        verbose=1,\n",
    "        shuffle=True,\n",
    "        validation_data=generator(features=X_val_prepro, labels=Y_val, batch_size=batch_size, patch_size=img_cols, \n",
    "                                  channels=channels, nb_classes=nb_classes),\n",
    "        validation_steps=validation_steps)\n",
    "\n",
    "plot_train_val_accuracy_and_loss(history_augmented, legend_suffix='augmented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model trained with augmented training data\n",
    "evaluation = my_model.evaluate(X_test_prepro, Y_test, batch_size=256, verbose=1)\n",
    "print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras already provides many CNN architectures including pre-trained weights\n",
    "\n",
    "For an easy start, check out: https://keras.io/applications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
